{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning of the pretrained Japanese BERT model\n",
    "\n",
    "Finetune the pretrained model to solve multi-class classification problems.  \n",
    "This notebook requires the following objects:\n",
    "- trained sentencepiece model (model and vocab files)\n",
    "- pretraiend Japanese BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/work/notebook/../config.ini']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "import tarfile \n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "CURDIR = os.getcwd()\n",
    "CONFIGPATH = os.path.join(CURDIR, os.pardir, 'config.ini')\n",
    "config = configparser.ConfigParser()\n",
    "config.read(CONFIGPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparing\n",
    "\n",
    "You need execute the following cells just once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEURL = config['FINETUNING-DATA']['FILEURL']\n",
    "FILEPATH = config['FINETUNING-DATA']['FILEPATH']\n",
    "EXTRACTDIR = config['FINETUNING-DATA']['TEXTDIR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and unzip data.  \n",
    "Dataset is livedoor ニュースコーパス in https://www.rondhuit.com/download.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlretrieve(FILEURL, FILEPATH)\n",
    "\n",
    "mode = \"r:gz\"\n",
    "tar = tarfile.open(FILEPATH, mode) \n",
    "tar.extractall(EXTRACTDIR) \n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_txt(filename):\n",
    "    with open(filename) as text_file:\n",
    "        # 0: URL, 1: timestamp\n",
    "        text = text_file.readlines()[2:]\n",
    "        text = [sentence.strip() for sentence in text]\n",
    "        text = list(filter(lambda line: line != '', text))\n",
    "        return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [ \n",
    "    name for name \n",
    "    in os.listdir( os.path.join(EXTRACTDIR, \"text\") ) \n",
    "    if os.path.isdir( os.path.join(EXTRACTDIR, \"text\", name) ) ]\n",
    "\n",
    "categories = sorted(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dokujo-tsushin',\n",
       " 'it-life-hack',\n",
       " 'kaden-channel',\n",
       " 'livedoor-homme',\n",
       " 'movie-enter',\n",
       " 'peachy',\n",
       " 'smax',\n",
       " 'sports-watch',\n",
       " 'topic-news']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans({\n",
    "    '\\n': '',\n",
    "    '\\t': '　',\n",
    "    '\\r': '',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = []\n",
    "all_label = []\n",
    "\n",
    "for cat in categories:\n",
    "    files = glob.glob(os.path.join(EXTRACTDIR, \"text\", cat, \"{}*.txt\".format(cat)))\n",
    "    files = sorted(files)\n",
    "    body = [ extract_txt(elem).translate(table) for elem in files ]\n",
    "    label = [cat] * len(body)\n",
    "    \n",
    "    all_text.extend(body)\n",
    "    all_label.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text' : all_text, 'label' : all_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=23).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data as tsv files.  \n",
    "test:dev:train = 2:2:6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:len(df) // 5].to_csv( os.path.join(EXTRACTDIR, \"test.tsv\"), sep='\\t', index=False)\n",
    "df[len(df) // 5:len(df)*2 // 5].to_csv( os.path.join(EXTRACTDIR, \"dev.tsv\"), sep='\\t', index=False)\n",
    "df[len(df)*2 // 5:].to_csv( os.path.join(EXTRACTDIR, \"train.tsv\"), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_PATH = '../model/model.ckpt-270000'\n",
    "FINETUNE_OUTPUT_DIR = '../model/livedoor_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../src/run_classifier.py \\\n",
    "  --task_name=livedoor \\\n",
    "  --do_train=true \\\n",
    "  --do_eval=true \\\n",
    "  --data_dir=../data/livedoor \\\n",
    "  --model_file=../model/wiki-ja.model \\\n",
    "  --vocab_file=../model/wiki-ja.vocab \\\n",
    "  --init_checkpoint={PRETRAINED_MODEL_PATH} \\\n",
    "  --max_seq_length=128 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --learning_rate=2e-5 \\\n",
    "  --num_train_epochs=3.0 \\\n",
    "  --output_dir={FINETUNE_OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using the finetuned model\n",
    "\n",
    "Let's predict test data using the finetuned model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import tokenization_sentencepiece as tokenization\n",
    "from run_classifier import LivedoorProcessor\n",
    "from run_classifier import model_fn_builder\n",
    "from run_classifier import file_based_input_fn_builder\n",
    "from run_classifier import file_based_convert_examples_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../bert\")\n",
    "\n",
    "import modeling\n",
    "import optimization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "def str_to_value(input_str):\n",
    "    \"\"\"\n",
    "    Convert data type of value of dict to appropriate one.\n",
    "    Assume there are only three types: str, int, float.\n",
    "    \"\"\"\n",
    "    if input_str.isalpha():\n",
    "        return input_str\n",
    "    elif input_str.isdigit():\n",
    "        return int(input_str)\n",
    "    else:\n",
    "        return float(input_str)\n",
    "\n",
    "bert_config_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.json')\n",
    "bert_config_file.write(json.dumps({k:str_to_value(v) for k,v in config['BERT-CONFIG'].items()}))\n",
    "bert_config_file.seek(0)\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ckpts = glob.glob(\"{}/model.ckpt*data*\".format('/tmp/livedoor_output'))\n",
    "latest_ckpt = sorted(output_ckpts)[-1]\n",
    "FINETUNED_MODEL_PATH = latest_ckpt.split('.data-00000-of-00001')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "    '''Parameters.'''\n",
    "    def __init__(self):\n",
    "        self.model_file = \"../model/wiki-ja.model\"\n",
    "        self.vocab_file = \"../model/wiki-ja.vocab\"\n",
    "        self.do_lower_case = True\n",
    "        self.use_tpu = False\n",
    "        self.output_dir = \"/dummy\"\n",
    "        self.data_dir = \"../data/livedoor\"\n",
    "        self.max_seq_length = 512\n",
    "        self.init_checkpoint = FINETUNED_MODEL_PATH\n",
    "        self.predict_batch_size = 16\n",
    "        \n",
    "        # The following parameters are not used in predictions.\n",
    "        # Just use to create RunConfig.\n",
    "        self.master = None\n",
    "        self.save_checkpoints_steps = 1\n",
    "        self.iterations_per_loop = 1\n",
    "        self.num_tpu_cores = 1\n",
    "        self.learning_rate = 0\n",
    "        self.num_warmup_steps = 0\n",
    "        self.num_train_steps = 0\n",
    "        self.train_batch_size = 0\n",
    "        self.eval_batch_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = FLAGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LivedoorProcessor()\n",
    "label_list = processor.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a trained SentencePiece model.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenization.FullTokenizer(\n",
    "    model_file=FLAGS.model_file, vocab_file=FLAGS.vocab_file,\n",
    "    do_lower_case=FLAGS.do_lower_case)\n",
    "\n",
    "tpu_cluster_resolver = None\n",
    "\n",
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    master=FLAGS.master,\n",
    "    model_dir=FLAGS.output_dir,\n",
    "    save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=FLAGS.iterations_per_loop,\n",
    "        num_shards=FLAGS.num_tpu_cores,\n",
    "        per_host_input_for_training=is_per_host))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f3e26d6aea0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/dummy', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3ddd2f0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1, num_shards=1, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
      "WARNING:tensorflow:Setting TPUConfig.num_shards==1 is an unsupported behavior. Please fix as soon as possible (leaving num_shards as None.)\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=len(label_list),\n",
    "    init_checkpoint=FLAGS.init_checkpoint,\n",
    "    learning_rate=FLAGS.learning_rate,\n",
    "    num_train_steps=FLAGS.num_train_steps,\n",
    "    num_warmup_steps=FLAGS.num_warmup_steps,\n",
    "    use_tpu=FLAGS.use_tpu,\n",
    "    use_one_hot_embeddings=FLAGS.use_tpu)\n",
    "\n",
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=FLAGS.use_tpu,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=FLAGS.train_batch_size,\n",
    "    eval_batch_size=FLAGS.eval_batch_size,\n",
    "    predict_batch_size=FLAGS.predict_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_examples = processor.get_test_examples(FLAGS.data_dir)\n",
    "predict_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.tf_record')\n",
    "\n",
    "file_based_convert_examples_to_features(predict_examples, label_list,\n",
    "                                        FLAGS.max_seq_length, tokenizer,\n",
    "                                        predict_file.name)\n",
    "\n",
    "predict_drop_remainder = True if FLAGS.use_tpu else False\n",
    "\n",
    "predict_input_fn = file_based_input_fn_builder(\n",
    "    input_file=predict_file.name,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=predict_drop_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = estimator.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will take a few hours on CPU.\n",
    "\n",
    "result = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'probabilities': array([6.3093408e-04, 3.1677485e-04, 2.3901617e-04, 1.1296889e-03,\n",
       "         7.7284197e-04, 8.3176029e-04, 7.1590225e-04, 9.9412304e-01,\n",
       "         1.2399884e-03], dtype=float32)},\n",
       " {'probabilities': array([2.3374568e-04, 7.7296095e-04, 9.9691844e-01, 3.6862720e-04,\n",
       "         2.6846604e-04, 2.7929764e-04, 5.5196742e-04, 2.6788114e-04,\n",
       "         3.3855080e-04], dtype=float32)}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read test data set and add prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../data/livedoor/test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict'] = [ label_list[elem['probabilities'].argmax()] for elem in result ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8472505091649695"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum( test_df['label'] == test_df['predict'] ) / len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A littel more detailed check using `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.96      0.83      0.89       178\n",
      "  it-life-hack       0.86      0.93      0.90       172\n",
      " kaden-channel       0.74      0.93      0.83       176\n",
      "livedoor-homme       0.83      0.83      0.83        95\n",
      "   movie-enter       1.00      0.65      0.78       158\n",
      "        peachy       0.63      0.91      0.75       174\n",
      "          smax       0.92      0.97      0.94       167\n",
      "  sports-watch       0.94      0.99      0.96       190\n",
      "    topic-news       0.98      0.54      0.70       163\n",
      "\n",
      "     micro avg       0.85      0.85      0.85      1473\n",
      "     macro avg       0.87      0.84      0.84      1473\n",
      "  weighted avg       0.87      0.85      0.84      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['label'], test_df['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147   1   2   2   0  25   1   0   0]\n",
      " [  0 160   3   4   0   3   2   0   0]\n",
      " [  0   9 164   0   0   2   1   0   0]\n",
      " [  1   4   5  79   0   6   0   0   0]\n",
      " [  0   1   1   2 102  51   0   1   0]\n",
      " [  1   0   4   3   0 158   8   0   0]\n",
      " [  0   3   1   0   0   1 162   0   0]\n",
      " [  0   0   0   0   0   0   0 188   2]\n",
      " [  4   7  41   5   0   4   2  12  88]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_df['label'], test_df['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
